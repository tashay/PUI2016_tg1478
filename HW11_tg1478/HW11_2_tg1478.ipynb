{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Clustering Time Trends for NYC Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Census Business data: http://www.census.gov/econ/cbp/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!for ((y=93; y<=99; y+=1)); do wget ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp$y\\totals.zip; done\n",
    "\n",
    "!for ((y=0; y<=9; y+=1)); do wget ftp://ftp.census.gov/econ200$y\\/CBP_CSV/zbp0$y\\totals.zip; done\n",
    "\n",
    "!for ((y=10; y<=15; y+=1)); do wget ftp://ftp.census.gov/econ20$y\\/CBP_CSV/zbp$y\\totals.zip; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfiles\n",
    "\n",
    "zf = zipfile.ZipFile(fname)\n",
    "df = pd.read_csv(zf.open(fname.replace('.zip','.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYC zip codes shape file: http://data.nycprepared.org/dataset/nyc-zip-code-tabulation-areas/resource/0c0e14e9-78e1-404e-97b0-c2fabceb3981"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you may need to clean your data: for some NYC zip codes there may be no info\n",
    "    \n",
    "sanity check: you should have 20 (N_timestamps) datapoints per time series and about 250 zipcodes (Nzipcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "IMPORTANT: we talked about the importance of \"whitening\" your data: dividing each feature by its standard deviation. \n",
    "Whitenings decorrelates the data: it makes the features independent so that the data covariance matrix is the identity matrix.\n",
    "Whitening your data in time series analysis is in most cases **wrong**: you are modifying your time behaviour. This is because of the strong correlation between features (two consecutive time stamps for the same observation, the same zip code here, are strongly correlated). Here instead you want to standardize your time series: subtract the mean and divide each time series (separately) by its standard deviation. As a sanity check (if you use skitlearn Kmeans or skitlearns kmeans2): you want your data array to be shaped Nzipcodes x Ntimestamps\n",
    "\n",
    "mydata.shape should be (Nzipcodes, Ntimestamps)\n",
    "\n",
    "mydata[i].std() shoould be 1 for all i in range(len(Nzipcodes))\n",
    "\n",
    "mydata[i].mean() should be ~0 for all i in range(len(Nzipcodes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "TASKS:\n",
    "    \n",
    "    1. get and prep your data.\n",
    "    2. cluster the NUMBER OF ESTABLISHMENTS time series with K-means in **a few** clusters (as discussed there is no real good, sound way to decide what a good number is here. try a few options, keeping in mind a few is more than a couple, but i recommand you stay within the single digit numbers)\n",
    "    3. plot the cluster centers (if you used K means those are the means of the clusters). you can plot for example the cluster centers overlayed on each time series (using the alpha channel to control the opacity in the plot may be helpful here).\n",
    "    4. Use another clustering algorithm (of your choice)\n",
    "    5. overlay your data on a NYC map: you can use shapefiles for the zip codes and different colors for different clusters\n",
    "    6. Compare the results of the 2 algorithms\n",
    "    7. attempt an interpretation. this is dangerous ground: clustering is an exploratory tool so you do not want to jump to conclusions because you see some clusters! but seeing structure in your data can inform your next moves as an investigator. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
